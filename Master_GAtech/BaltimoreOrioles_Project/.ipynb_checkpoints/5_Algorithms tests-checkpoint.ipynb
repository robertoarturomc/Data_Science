{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, mean_squared_error, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3877, 71)\n",
      "(9880, 71)\n",
      "(3877,)\n",
      "(9880,)\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.read_pickle('Datasets/X_train2.plk')\n",
    "X_test=pd.read_pickle('Datasets/X_test.plk')\n",
    "y_train=pd.read_pickle('Datasets/y_train2.plk')\n",
    "y_test=pd.read_pickle('Datasets/y_test.plk')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three algorithms were tested, to know if they are suitable for capturing the differences between the last plate apperances for the pitchers, and a \"normal\" plate appearance.\n",
    "They are simple algorithms, whose decision boundaries may be calculated by hand.\n",
    "\n",
    "Different parameters were randomly tested and all of the variables were used. Here, the \"best\" results are shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(random_state=42, penalty='none', max_iter=10000)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lr.predict(X_test)\n",
    "\n",
    "pd.crosstab(y_test, y_pred, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( accuracy_score(y_test, (y_pred>0.5)+0 ))\n",
    "print( precision_score(y_test, (y_pred>0.5)+0 ))\n",
    "print( roc_auc_score(y_test, (y_pred>0.5)+0 ))\n",
    "print( f1_score(y_test, (y_pred>0.5)+0 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=SVC(kernel='linear', C=0.5)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=svm.predict(X_test)\n",
    "\n",
    "pd.crosstab(y_test, np.round(y_pred2,0), margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( accuracy_score(y_test, (y_pred2>0.5)+0 ))\n",
    "print( precision_score(y_test, (y_pred2>0.5)+0 ))\n",
    "print( roc_auc_score(y_test, (y_pred2>0.5)+0 ))\n",
    "print( f1_score(y_test, (y_pred2>0.5)+0 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "\n",
    "X_train=train.iloc[:,0:67]\n",
    "y_train=train.iloc[:,69]\n",
    "\n",
    "#X_test=test.iloc[:,0:67]\n",
    "#y_test=test.iloc[:,68]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DecisionTreeClassifier(max_depth=3, criterion='gini', random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "## ¡¡VOLVER A ENCONTRAR DATOS QUE PRODUCEN F1=40!!!\n",
    "## ¡¡GUARDAR ESE MODELO!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3=tree.predict(X_test[X_train.columns.tolist()])\n",
    "\n",
    "pd.crosstab(y_test, (y_pred3>0.5)+0, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( accuracy_score(y_test, (y_pred3>0.5)+0 ))\n",
    "print( precision_score(y_test, (y_pred3>0.5)+0 ))\n",
    "print( roc_auc_score(y_test, (y_pred3>0.5)+0 ))\n",
    "print( f1_score(y_test, (y_pred3>0.5)+0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[tree.feature_importances_>0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three algorithms performed similar. In particular, the SVM and the Logistic Regression had a similar prediction on the testing set. That was expected, as they both aim to generate the best “hyperplane” that separates the two classes. However, the logistic regression runs noticeably faster, and has a more concise formula to determine the decision boundary. Therefore, it will be chosen over the SVM with a linear kernel.\n",
    "\n",
    "On the other hand, the Decision Tree performed slightly better on most of the metrics while using less variables. That is because the maximum depth was set at four. Thus, the Decision Tree will be used as a base model, while we attempt to have a better model by using a Logistic Regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( export_text(tree,  feature_names=X_train.columns.tolist()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
